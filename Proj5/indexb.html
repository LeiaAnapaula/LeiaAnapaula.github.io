<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Proj 5 — Part B</title>

    <style>
        :root {
            --berkeley-blue: #003262;
            --founders-rock: #C4820E;
            --medalist: #D9661F;
            --light-gray: #EEEEEE;
        }

        body {
            font-family: Arial, sans-serif;
            margin: 0;
            padding: 0 40px 80px 40px;
            background-color: var(--light-gray);
        }

        h1, h2, h3 {
            font-weight: 600;
            color: var(--berkeley-blue);
        }

        nav {
            background: var(--berkeley-blue);
            padding: 15px;
            color: white;
            position: sticky;
            top: 0;
            border-bottom: 4px solid var(--founders-rock);
        }

        nav a {
            color: var(--founders-rock);
            margin-right: 15px;
            text-decoration: none;
            font-weight: 600;
        }

        nav a:hover {
            color: var(--medalist);
        }

        section {
            margin-top: 55px;
        }

        img {
            max-width: 100%;
            margin: 10px 0;
            border-radius: 6px;
        }

        .sub {
            margin-left: 20px;
        }
    </style>
</head>

<body>

<nav>
    <a href="#top">Proj5</a>
    <a href="#p1">Part 1</a>
    <a href="#p121">1.2.1</a>
    <a href="#p122">1.2.2</a>
    <a href="#p123">1.2.3</a>
    <a href="#p2">Part 2</a>
    <a href="#p22">2.2</a>
    <a href="#p23">2.3</a>
    <a href="#p25">2.5</a>
    <a href="#p26">2.6</a>
</nav>

<h1 id="top">CS180 Project 5 — Part B</h1>
<h2>Flow Matching from Scratch</h2>

<!-- ===================== PART 1 ===================== -->
<section id="p1">
    <h2>Part 1 — Single-step Denoising UNet</h2>
    <p class="sub">
        In Part 1, we train a UNet denoiser on MNIST with Gaussian noise and evaluate it under different noise levels.
    </p>
</section>

<!-- ===================== 1.2.1 ===================== -->
<section id="p121">
    <h2>1.2.1 — Training a Denoiser (σ = 0.5)</h2>
    <p class="sub">
        Train a UNet denoiser on MNIST with noise level σ = 0.5. Below are the training loss curve and sample denoising results.
    </p>

    <h3>Training Loss Curve</h3>
    <img src="results/1_2_noise_levels/loss_curve.png" alt="1.2.1 training loss curve">

    <h3>Sample Results (Epoch 1)</h3>
    <img src="results/1_2_noise_levels/epoch_1.png" alt="1.2.1 epoch 1 results">

    <h3>Sample Results (Epoch 5)</h3>
    <img src="results/1_2_noise_levels/epoch_5.png" alt="1.2.1 epoch 5 results">
</section>

<!-- ===================== 1.2.2 ===================== -->
<section id="p122">
    <h2>1.2.2 — Out-of-Distribution Testing</h2>
    <p class="sub">
        We test the denoiser (trained at σ = 0.5) on a fixed test image while varying σ ∈ [0.0, 0.2, 0.4, 0.5, 0.6, 0.8, 1.0].
    </p>

    <img src="results/1_2_2_ood/ood_grid.png" alt="1.2.2 OOD denoising grid">
</section>

<!-- ===================== 1.2.3 ===================== -->
<section id="p123">
    <h2>1.2.3 — Denoising Pure Noise</h2>
    <p class="sub">
        We train a denoiser to map pure Gaussian noise z ~ N(0, I) into clean MNIST digits. Below are the training curve and samples after epoch 1 and 5.
    </p>

    <h3>Training Loss Curve</h3>
    <img src="results/1_2_3_pure_noise/loss_curve.png" alt="1.2.3 training loss curve">

    <h3>Samples (Epoch 1)</h3>
    <img src="results/1_2_3_pure_noise/epoch_1.png" alt="1.2.3 epoch 1 samples">

    <h3>Samples (Epoch 5)</h3>
    <img src="results/1_2_3_pure_noise/epoch_5.png" alt="1.2.3 epoch 5 samples">
</section>

<!-- ===================== PART 2 ===================== -->
<section id="p2">
    <h2>Part 2 — Flow Matching Model</h2>
    <p class="sub">
        In Part 2, we train a time-conditioned UNet to predict the flow field for iterative denoising, then extend it to class conditioning with classifier-free guidance (CFG).
    </p>
</section>

<!-- ===================== 2.2 ===================== -->
<section id="p22">
    <h2>2.2 — Training the Time-Conditioned UNet</h2>
    <p class="sub">
        Train a time-conditioned UNet using flow matching. Below is the training loss curve over the full training process.
    </p>

    <img src="results/2_2_time_fm/loss_curve.png" alt="2.2 training loss curve">
</section>

<!-- ===================== 2.3 ===================== -->
<section id="p23">
    <h2>2.3 — Sampling from the Time-Conditioned UNet</h2>
    <p class="sub">
        Samples produced via iterative denoising after 1, 5, and 10 epochs.
    </p>

    <h3>Epoch 1</h3>
    <img src="results/2_3_time_fm/epoch_1.png" alt="2.3 epoch 1 samples">

    <h3>Epoch 5</h3>
    <img src="results/2_3_time_fm/epoch_5.png" alt="2.3 epoch 5 samples">

    <h3>Epoch 10</h3>
    <img src="results/2_3_time_fm/epoch_10.png" alt="2.3 epoch 10 samples">
</section>

<!-- ===================== 2.5 ===================== -->
<section id="p25">
    <h2>2.5 — Training the Class-Conditioned UNet</h2>
    <p class="sub">
        Train the class-conditioned UNet with classifier-free dropout (p_uncond = 0.1). Below is the training loss curve.
    </p>

    <img src="results/2_5_class_fm/loss_curve.png" alt="2.5 class-conditioned training loss">
</section>

<!-- ===================== 2.6 ===================== -->
<section id="p26">
    <h2>2.6 — Class-Conditional Sampling with CFG (γ = 5.0)</h2>
    <p class="sub">
        Generate 4 instances of each digit (0–9) using classifier-free guidance with γ = 5.0, shown after 1, 5, and 10 epochs.
    </p>

    <h3>Epoch 1</h3>
    <img src="results/2_6_class_cfg/epoch_1_cfg5.0.png" alt="2.6 epoch 1 CFG samples">

    <h3>Epoch 5</h3>
    <img src="results/2_6_class_cfg/epoch_5_cfg5.0.png" alt="2.6 epoch 5 CFG samples">

    <h3>Epoch 10</h3>
    <img src="results/2_6_class_cfg/epoch_10_cfg5.0.png" alt="2.6 epoch 10 CFG samples">
</section>

</body>
</html>
